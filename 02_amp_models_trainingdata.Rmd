---
title: "Training datasets in other AMP predictors"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(ampir)
library(tidyverse)
```

# Introduction

The effectiveness of supervised learning methods for predictive modeling is highly affected by the data that were used to train the model with. Supervised learning is a part of machine learning which finds patterns between data characteristics and labels that are assigned to the training data used to facilitate learning of the model. Once the model has been trained, it can then predict which label fits best from new data it is used or tested on. 

# AMP predictor data

**iAMP-2L Data**

The benchmark data provided by [Xiao et al. 2013](https://doi.org/10.1016/j.ab.2013.01.019) used for [iAMP-2L](http://www.jci-bioinfo.cn/iAMP/data.html) has been used in several studies to provide a somewhat independent estimate of prediction accuracy. Their training data, or benchmark dataset as they termed it, comprises of 897 AMPs and 2,405 non-AMPs. Their test or independent dataset comprises of 920 AMPs and 920 non-AMPs.  

```{r}
iAMP2L_train <- read_faa("data/amp_predictors/iAMP-2L/xiao_benchmark.fasta") %>% 
  mutate(class = ifelse(grepl(seq_name,pattern = "^AP"), "AMP", "non-AMP")) %>% 
  distinct(seq_name, .keep_all = TRUE) %>%
  add_column(dataset="Train") 
  
iAMP2L_test <- read_faa("data/amp_predictors/iAMP-2L/xiao_independent.fasta") %>% 
  mutate(class = ifelse(grepl(seq_name,pattern = "^AP"), "AMP", "non-AMP")) %>%
  add_column(dataset="Test") 
  
iAMP2L <- rbind(iAMP2L_train, iAMP2L_test) %>%
  mutate(length = nchar(seq_aa)) %>% add_column(database="iAMP-2L")

```

**AmPEP Training Data**

The AmPEP 2018 AMP predictor provides its training data available directly for download from [https://cbbio.cis.um.edu.mo/software/AmPEP/](https://cbbio.cis.um.edu.mo/software/AmPEP/). The final training dataset used by amPEP is a large dataset of 166,791 non-AMP sequences and 3,268 AMPs. amPEP used the Xiao et al. 2013 dataset from the iAMP-2L predictor as a test set (see above).  

```{r}
ampep_data <- read_faa("data/amp_predictors/amPEP/M_model_train_nonAMP_sequence.fasta") %>% add_column(class="non-AMP") %>% 
  rbind(read_faa("data/amp_predictors/amPEP/M_model_train_AMP_sequence.fasta") %>% add_column(class="AMP")) %>% 
  mutate(length = nchar(seq_aa)) %>% add_column(predictor="AmPEP") %>%
  mutate(seq_name = paste0("amPEP_trainset_neg", 1:n()))
```

AmPEP was redesigned in 2020 as Deep-AmPEP30 to focus on short AMPs ( < 30 amino acids) by [Yan et al](https://doi.org/10.1016/j.omtn.2020.05.006) and its training and test data is available [here](https://cbbio.online/AxPEP/?action=dataset).

```{r}
deep_ampep_data <- read_faa("data/amp_predictors/deepamPEP30/train_ne.fasta") %>%
   rbind(read_faa("data/amp_predictors/deepamPEP30/test_ne.fasta")) %>%
  add_column(class = "non-AMP") %>%
  rbind(read_faa("data/amp_predictors/deepamPEP30/train_po.fasta") %>%
  rbind(read_faa("data/amp_predictors/deepamPEP30/test_po.fasta")) %>%
          add_column(class = "AMP")) %>%
  mutate(dataset = case_when(
    str_detect(seq_name, "^test") ~ "Test",
    str_detect(seq_name, "^uni") ~ "Test",
                             TRUE ~ "Train")) %>%
  mutate(length = nchar(seq_aa)) %>% 
  add_column(predictor="deep_AmPEP")

```


AmPEP was additionally created as a python application, amPEPpy, by [Lawrence et al. 2020](https://doi.org/10.1093/bioinformatics/btaa917). amPEPpy's training data originated from amPEP and were obtained via amPEPpy's [GitHub page](https://github.com/tlawrence3/amPEPpy).

```{r}
ampeppy_data <- read_faa("data/amp_predictors/amPEPpy/M_model_train_nonAMP_sequence.numbered.proplen.subsample.fasta") %>% add_column(class="non-AMP") %>% 
  rbind(read_faa("data/amp_predictors/amPEPpy/M_model_train_AMP_sequence.numbered.fasta") %>% add_column(class="AMP")) %>% 
  mutate(length = nchar(seq_aa)) %>% add_column(predictor="AmPEPpy")
```

**AMP Scanner v2 Data**

AMP Scanner ([Veltri et al. 2018](https://doi.org/10.1093/bioinformatics/bty179])) data used for training, testing and evaluation are available directly for download from [https://www.dveltri.com/ascan/v2/about.html](https://www.dveltri.com/ascan/v2/about.html). AMP Scanner's training data consisted of 1,066 AMP and non-AMP sequences. Their testing data consisted of 712 AMP and non-AMP sequences. 

```{r}
ampscan_train_data <- read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/AMP.tr.fa") %>%
   rbind(read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/AMP.eval.fa")) %>%
  rbind(read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/DECOY.tr.fa")) %>%
  rbind(read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/DECOY.eval.fa")) %>%
             add_column(dataset="Train")

ampscan_test_data <- rbind(read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/AMP.te.fa")) %>%
  rbind(read_faa("data/amp_predictors/AMP_Scan2_OrigPaper_Dataset/DECOY.te.fa")) %>%
             add_column(dataset="Test")

ampscan_data <- rbind(ampscan_train_data, ampscan_test_data) %>%
  mutate(class = case_when(str_detect(seq_name, "^Uni") ~ "non-AMP", TRUE ~ "AMP")) %>%
    mutate(length = nchar(seq_aa)) %>% 
    add_column(predictor="AMP Scanner v2")
```

**AMPlify data**

AMPlify used multiple attention mechanisms and ensemble deep learning to create an AMP prediction model ([Li et al. 2020](https://doi.org/10.1101/2020.06.16.155705)). Similar to most AMP predictors, a proportion of their AMP dataset originated from the general [Antimicrobial Peptide Database](http://aps.unmc.edu/AP). However, they also used the [Database of Anuran Defense Peptides](http://split4.pmfst.hr/dadp/0) which focuses on AMPs from frogs and toads. Their negative dataset originated from Swiss-Prot and, like most AMP predictors, they excluded any proteins that had annotations which referred to potential antimicrobial activity. However, like ampir, they retain the secreted proteins.

Their data is available from the [AMPlify's software GitHub page](https://github.com/bcgsc/AMPlify). Their training set consists of 3,338 AMPs and 3,338 non-AMPs and their test set consists of 835 AMPs and 835 non-AMPs.


