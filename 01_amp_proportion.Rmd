---
title: "Precision recall for AMP proportions in a genome"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


```{r}
library(tidyverse)
library(caret)
library(patchwork)
library(viridis)

source("R/calc_cm_metrics.R")
```

To start, we read in ampir's v_0.1 trained model as well as the test dataset
```{r}
ampir_v0.1 <- readRDS("ampir_0.1.0_data/svm_Radial98_final.rds")
features98Test <- readRDS("ampir_0.1.0_data//features98TestNov19.rds")
```

calculate precision recall auc
```{r}

library("precrec")

sscurves <- evalmod(scores = ampir_prob_data$Tg, labels = ampir_prob_data$actual)

auc(evalmod(scores = ampir_prob_data$Tg, labels = ampir_prob_data$actual)
)

autoplot(sscurves)
```


We then use the ampir model to predict the proteins in the test set. We then add the actual cases to the prediction outcome.
```{r}

test_pred_prob <- predict(ampir_v0.1, features98Test, type = "prob")

ampir_prob_data<- test_pred_prob %>%
  add_column(actual = features98Test$Label)
```

To create an idea what to set the probability threshold to for AMP prediction in genomes, a (precision recall (recall aka sensitivity) probability curve was constructed using a dataset where AMPs only comprise approximately 1% (10/996).`

```{r}
#extract the actual/true Bg cases
prob_pred_bg <- ampir_prob_data[grep("Bg", ampir_prob_data$actual),]
#extract 10 random true Tg as 1% representative
prob_pred_tg_10 <- ampir_prob_data[sample(grep("Tg", ampir_prob_data$actual), 10),]
#rbind together
prob_pred_bg_tg10 <- rbind(prob_pred_tg_10, prob_pred_bg)
```

We then use the function `calc_cm_metrics` to calculate a confusion matrix and some associated performance metrics over a range of predicted probability values. The original output of the function is a vector. To use multiple probability threshold, `sapply` is used for iteration.
`t` is used to transpose the matrix result from `sapply` and then `as.data.frame` is used to convert the matrix to a dataframe.

```{r}
#calculate metrics
pr_curve_sample <- as.data.frame(t(sapply(seq(0.01, 0.99, 0.01), calc_cm_metrics, prob_pred_bg_tg10)))
#convert to long format for plotting
pr_curve_sample_long <- pr_curve_sample[,c(6,7,9)] %>%
  gather("metric", "value", 1:2)
```


```{r}
ggplot(pr_curve_sample_long, aes(x=p_threshold, y=value)) +
  geom_line(aes(color = metric)) 
```

1% is a very small proportion and the curve is creating "big steps". To try to circumvent it, 100 random selection of 1% (10 AMPs) were used to average the curves.

the `samples_list_x` variable is created using the `lapply`, `seq_along` and `function` combination

```{r}
#select 10 random AMPs 100 different times to get 100 dataframes and place in list
samples_list <- replicate(n = 100,
                     expr = {ampir_prob_data[sample(grep("Tg", ampir_prob_data$actual), 10),]},
                     simplify = F)

#rbind the bg (prob_pred_bg) dataset to each tg replicate and add a sample column to each dataframe in the list as reference point
samples_list_x <- lapply(seq_along(samples_list), function(i) {
                      df <- samples_list[[i]]
                      df <- df %>% rbind(prob_pred_bg)
                      df %>% add_column(sample = i)
})

```
cannot use `calc_cm_metrics` on a list (only works on 1 at a time) so made wonky loop to circumvent it
```{r}
metric_list <- lapply(seq_along(samples_list_x), function(i) {
                 as.data.frame(t(sapply(seq(0.01, 0.99, 0.01),
                                        calc_cm_metrics, 
                                        samples_list_x[[i]])))
})
```


Now I have a list with 100 dfs in it that each contain metrics calculated with `calc_cm_metrics` from 100 dfs that each contain 10 random AMPs and 996 background proteins.

I want to average the precision and recall columns over the 0.01 - 0.99 p_threshold range.
To do this I bind all the dfs in the list together into one big df. Then I use the `group_by` function to group the df by the p_threshold and then use `summarise` to create two new columns that contain the calculated average of precision and recall. finally convert it into long format again.
```{r}
bound_metrics <- bind_rows(metric_list)


pr_averages_with_p_threshold <- bound_metrics %>% 
                                group_by(p_threshold) %>% 
                                summarise(Precision_average = mean(Precision), 
                                          Recall_average = mean(Recall)) 

pr_averages_with_p_threshold_long <- pr_averages_with_p_threshold %>% 
                                    gather("metric", "value", 2:3)

#the precision average for 0.99 probability is NaN so replace it with 1
pr_averages_with_p_threshold_long <- as.data.frame(pr_averages_with_p_threshold_long)
pr_averages_with_p_threshold_long$value[which(is.na(pr_averages_with_p_threshold_long$value))] <- 1
```


### Average plot using an everage of 1% AMPs in a test set, 100 times

```{r}
ggplot(pr_averages_with_p_threshold_long, aes(x=p_threshold, y=value)) +
  geom_line(aes(color = metric)) + 
  scale_x_continuous(breaks=c(0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  scale_colour_manual(values = c("blueviolet", "forestgreen"),
                      labels = c("Precision", "Recall")) +
  labs(x = "Probability threshold", y = "", color = "") +
  theme(legend.position = c(0.23, 0.53),
        legend.key = element_rect(fill = "white"),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "grey")) +
  guides(color = guide_legend(reverse=TRUE)) +
  ggtitle("A")

```

## Theoretical AMP content - alpha 

A new variable, $\alpha$, was introduced to represent the percentage of AMPs in the test set to more easily create precision-recall curves for various AMP proportions. The calculation for the recall metric for $\alpha$ remains the same but the precision metric has been slightly modified (see below):


$$Precision_{\alpha} = \frac{TP\alpha}{TP\alpha + FP(1-\alpha)}$$

$$Recall_{\alpha} = \frac{TP}{TP + FN}$$

Function that uses the recall-precision metric calculations for any $alpha$ value
```{r}
calc_precision_recall <- function(df,alpha) {
  df %>% 
  mutate(Recall = Recall) %>% 
  mutate(Precision = TP*alpha / (TP*alpha+FP*(1-alpha))) %>% 
  select(Recall,Precision,p_threshold)
}
```

Use the function for a range of $alpha$ values and collapse to data frame

```{r}
pr_data <- do.call(rbind,lapply(c(0.01,0.05,0.1,0.5),function(alpha) {
  calc_precision_recall(ampir_roc_data,alpha) %>% add_column(alpha=alpha)
}))
```


Plot an explicit axis for `p_threshold`. This is useful for choosing the threshold value. Also note that as $\alpha$ gets smaller and smaller the Precision curve shifts so that high values of precision are only achieved for very high `p_threshold` values.

```{r}
pr_data_long <- pr_data %>% gather("metric","value",-p_threshold,-alpha)


variable_names <- c("0.01" = "Proportion of AMPs in genome: 0.01",
                    "0.05" = "Proportion of AMPs in genome: 0.05",
                    "0.1" = "Proportion of AMPs in genome: 0.10",
                    "0.5" = "Proportion of AMPs in genome: 0.50")

ggplot(pr_data_long,aes(x=p_threshold,y=value)) + 
  geom_line(aes(colour=metric)) + facet_wrap(~alpha, labeller= as_labeller(variable_names)) +
  labs(x = "Probability threshold", y = "", colour = "") +
  scale_x_continuous(breaks=c(0, 0.50, 1.00)) +
  scale_y_continuous(breaks=c(0, 0.50, 1.00)) +
  scale_colour_manual(values = c("blueviolet", "forestgreen")) +
  theme(legend.position = "left",
        legend.text = element_text(angle = 90, hjust = 0.5),
        legend.margin = margin(0,0,0,8),
        legend.box.margin=margin(-10,-10,-10,-10),
        legend.key = element_rect(fill = "white"),
        legend.key.height = unit(2, "cm"),
        legend.box.spacing = unit(0.1, "cm"),
        panel.background = element_blank(),
        axis.line = element_line(colour = "grey")) +
  guides(linetype = guide_legend(reverse=TRUE))
```


```{r}
ggsave("figures/alphas.png", width = 7, height=5)
```

Plot using a traditional precision vs recall curve.  This is useful in the sense that it very clearly shows the tradeoff between the two. A useful way to think of Precision is that it defines the "Purity" of our predicted set of AMPs whereas the Sensitivity or Recall defines the "Completeness" of the predicted AMP set.  We want to choose the p_threshold so that there is a balance or Purity and Completeness.  When `alpha` is high this is easy to do, but when it is low it becomes a very difficult tradeoff.

```{r}
ggplot(pr_data, aes(x=Recall, y=Precision)) +
  geom_line(aes(group=as.factor(alpha), colour = as.factor(alpha))) + 
  scale_color_viridis(discrete = TRUE) +
  theme(legend.key = element_rect(fill = "white"),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "grey")) +
  labs(colour = "alpha") +
   guides(color = guide_legend(reverse=TRUE))

ggsave("figures/alpha_gradient.png", height = 5, width = 7)
```


Extract 1% alpha value
```{r}
pr_data_alpha1_long <- pr_data_long %>% filter(alpha == 0.01)
```

```{r}
ggplot(filter(pr_data_alpha1_long, p_threshold >= 0.5), aes(x=p_threshold, y=value)) + 
  geom_line(aes(colour = metric)) + 
  labs(x = "Probability threshold", y = "", colour = "") +
  scale_colour_manual(values = c("blueviolet", "forestgreen")) +
  scale_x_continuous(breaks=c(0.50, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  scale_y_continuous(breaks=c(0.10, 0.50, 1.00)) +
  theme(legend.position = c(0.2, 0.5),
        panel.background = element_blank(),
        legend.key=element_blank(),
        axis.line = element_line(colour = "grey")) +
  guides(colour = guide_legend(reverse = TRUE)) +
  ggtitle("B")

```

## Comparing theoretical alpha plot with real average content

```{r}
average_plot1perc <- ggplot(pr_averages_with_p_threshold_long, aes(x=p_threshold, y=value)) +
  geom_line(aes(color = metric)) + 
  scale_x_continuous(breaks=c(0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  scale_colour_manual(values = c("blueviolet", "forestgreen"),
                      labels = c("Precision", "Recall")) +
  labs(x = "", y = "", color = "") +
  theme(legend.position = c(0.23, 0.53),
        legend.key = element_rect(fill = "white"),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "grey")) +
  guides(color = guide_legend(reverse=TRUE)) +
  ggtitle("A")

alpha_001plot <- ggplot(filter(pr_data_alpha1_long, p_threshold >= 0.5), aes(x=p_threshold, y=value)) + 
  geom_line(aes(colour = metric)) + 
  labs(x = "Probability threshold", y = "", colour = "") +
  scale_colour_manual(values = c("blueviolet", "forestgreen")) +
  scale_x_continuous(breaks=c(0.50, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  scale_y_continuous(breaks=c(0.10, 0.50, 1.00)) +
  theme(legend.position = c(0.2, 0.5),
        panel.background = element_blank(),
        legend.key=element_blank(),
        axis.line = element_line(colour = "grey")) +
  guides(colour = guide_legend(reverse = TRUE)) +
  ggtitle("B")

average1percvsalpha1pc <- average_plot1perc / alpha_001plot

ggsave("figures/alpha_vs_average.png", average1percvsalpha1pc)
```

